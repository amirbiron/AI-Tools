import sqlite3
import json
import pickle
import numpy as np
from sentence_transformers import SentenceTransformer
import faiss
import re
from typing import List, Dict, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class AIToolsSemanticSearch:
    def __init__(self, db_path='ai_tools_full.db'):
        self.db_path = db_path
        self.model = None
        self.index = None
        self.tools_data = []
        self.embeddings = None
        
        # ×˜×¢×Ÿ ××•×“×œ embedding (×§×˜×Ÿ ×•××”×™×¨)
        logger.info("ğŸ¤– ×˜×•×¢×Ÿ ××•×“×œ ×¢×‘×¨×™×ª/×× ×’×œ×™×ª...")
        self.model = SentenceTransformer('all-MiniLM-L6-v2')
        logger.info("âœ… ××•×“×œ × ×˜×¢×Ÿ ×‘×”×¦×œ×—×”")
        
        self.load_tools_from_db()
        self.setup_search_index()
    
    def load_tools_from_db(self):
        """×˜×¢×™× ×ª ×›×œ×™× ×××¡×“ ×”× ×ª×•× ×™×"""
        logger.info("ğŸ“Š ×˜×•×¢×Ÿ ×›×œ×™× ×××¡×“ ×”× ×ª×•× ×™×...")
        
        conn = sqlite3.connect(self.db_path)
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT name, url, description, category, popularity, pricing, tags 
            FROM ai_tools 
            WHERE description IS NOT NULL AND description != ""
            ORDER BY name
        ''')
        
        rows = cursor.fetchall()
        
        for row in rows:
            tool = {
                'name': row[0],
                'url': row[1], 
                'description': row[2],
                'category': row[3] or '',
                'popularity': row[4] or '',
                'pricing': row[5] or '',
                'tags': row[6] or ''
            }
            self.tools_data.append(tool)
        
        conn.close()
        
        logger.info(f"âœ… × ×˜×¢× ×• {len(self.tools_data)} ×›×œ×™ AI")
        
        if len(self.tools_data) == 0:
            raise Exception("×œ× × ××¦××• ×›×œ×™× ×‘××¡×“ ×”× ×ª×•× ×™×!")
    
    def create_search_text(self, tool):
        """×™×¦×™×¨×ª ×˜×§×¡×˜ ×××•×—×“ ×œ×—×™×¤×•×©"""
        parts = [
            tool['name'],
            tool['description'],
            tool['category'],
            tool['tags']
        ]
        
        # × ×§×” ×•×—×‘×¨
        search_text = ' '.join([part.strip() for part in parts if part.strip()])
        
        # × ×§×” ××ª×•×•×™× ××™×•×—×“×™×
        search_text = re.sub(r'[^\w\s]', ' ', search_text)
        search_text = re.sub(r'\s+', ' ', search_text).strip()
        
        return search_text
    
    def setup_search_index(self):
        """×‘× ×™×™×ª ××™× ×“×§×¡ ×—×™×¤×•×©"""
        logger.info("ğŸ”§ ×‘×•× ×” ××™× ×“×§×¡ ×—×™×¤×•×© ×¡×× ×˜×™...")
        
        # ×™×¦×•×¨ ×˜×§×¡×˜ ×œ×—×™×¤×•×© ×œ×›×œ ×›×œ×™
        search_texts = []
        for tool in self.tools_data:
            search_text = self.create_search_text(tool)
            search_texts.append(search_text)
        
        # ×™×¦×•×¨ embeddings
        logger.info("âš¡ ×™×•×¦×¨ embeddings...")
        self.embeddings = self.model.encode(search_texts)
        
        # ×™×¦×•×¨ FAISS index
        logger.info("ğŸ“Š ×‘×•× ×” FAISS index...")
        dimension = self.embeddings.shape[1]
        self.index = faiss.IndexFlatIP(dimension)  # Inner Product (××”×™×¨)
        
        # × ×¨××œ embeddings ×¢×‘×•×¨ cosine similarity
        faiss.normalize_L2(self.embeddings)
        self.index.add(self.embeddings.astype('float32'))
        
        logger.info(f"âœ… ××™× ×“×§×¡ ×—×™×¤×•×© ××•×›×Ÿ ×¢× {len(self.tools_data)} ×›×œ×™×")
    
    def preprocess_query(self, query):
        """×¢×™×‘×•×“ ××§×“×™× ×©×œ ×”×©××œ×”"""
        # ×”××¨×” ×œ×× ×’×œ×™×ª ×©×œ ××™×œ×™× × ×¤×•×¦×•×ª ×‘×¢×‘×¨×™×ª
        hebrew_to_english = {
            '×¦\'××˜': 'chat',
            '×¦××˜': 'chat', 
            '×‘×•×˜': 'bot',
            '×ª××•× ×”': 'image',
            '×ª××•× ×•×ª': 'image',
            '×•×™×“××•': 'video',
            '×•×™×“×™×•': 'video',
            '×¡×¨×˜×•×Ÿ': 'video',
            '×˜×§×¡×˜': 'text',
            '×›×ª×™×‘×”': 'writing',
            '×¢×™×¦×•×‘': 'design',
            '×™×¦×™×¨×”': 'generation create',
            '×—×™× ××™': 'free',
            '×‘×—×™× ×': 'free',
            '×‘×ª×©×œ×•×': 'paid',
            '×¢×¨×™×›×”': 'editing',
            '×§×•×“': 'code',
            '×ª×›× ×•×ª': 'programming code',
            '××ª×¨': 'website',
            '×œ×•×’×•': 'logo',
            '××•×¡×™×§×”': 'music',
            '×§×•×œ': 'voice audio',
            '×ª×¨×’×•×': 'translation',
            '×©×¤×”': 'language'
        }
        
        # ×”×—×œ×£ ××™×œ×™× ×‘×¢×‘×¨×™×ª
        for hebrew, english in hebrew_to_english.items():
            query = query.replace(hebrew, english)
        
        # × ×§×”
        query = re.sub(r'[^\w\s]', ' ', query)
        query = re.sub(r'\s+', ' ', query).strip()
        
        return query
    
    def search(self, query, top_k=10):
        """×—×™×¤×•×© ×¡×× ×˜×™"""
        if not query.strip():
            return []
        
        # ×¢×‘×“ ×©××œ×”
        processed_query = self.preprocess_query(query)
        logger.info(f"ğŸ” ××—×¤×©: '{query}' -> '{processed_query}'")
        
        # ×™×¦×•×¨ embedding ×œ×©××œ×”
        query_embedding = self.model.encode([processed_query])
        faiss.normalize_L2(query_embedding)
        
        # ×—×™×¤×•×©
        scores, indices = self.index.search(query_embedding.astype('float32'), top_k)
        
        # ×”×›×Ÿ ×ª×•×¦××•×ª
        results = []
        for i, (score, idx) in enumerate(zip(scores[0], indices[0])):
            if idx >= len(self.tools_data):
                continue
                
            tool = self.tools_data[idx].copy()
            tool['relevance_score'] = float(score)
            tool['rank'] = i + 1
            
            # ×—×©×‘ × ×§×•×“×•×ª ×¤×•×¤×•×œ×¨×™×•×ª
            popularity_bonus = 0
            if tool['popularity']:
                try:
                    pop_num = int(tool['popularity'].replace('+', '').replace(',', ''))
                    popularity_bonus = min(pop_num / 10000, 0.1)  # ××§×¡×™××•× 0.1 ×‘×•× ×•×¡
                except:
                    pass
            
            tool['final_score'] = score + popularity_bonus
            results.append(tool)
        
        # ××™×™×Ÿ ×œ×¤×™ ×¦×™×•×Ÿ ×¡×•×¤×™
        results.sort(key=lambda x: x['final_score'], reverse=True)
        
        logger.info(f"âœ… × ××¦××• {len(results)} ×ª×•×¦××•×ª")
        return results
    
    def search_by_category(self, category, top_k=20):
        """×—×™×¤×•×© ×œ×¤×™ ×§×˜×’×•×¨×™×”"""
        results = []
        
        for i, tool in enumerate(self.tools_data):
            if category.lower() in tool['category'].lower():
                tool_copy = tool.copy()
                tool_copy['rank'] = len(results) + 1
                tool_copy['relevance_score'] = 1.0
                results.append(tool_copy)
                
                if len(results) >= top_k:
                    break
        
        return results
    
    def get_categories(self):
        """×§×‘×œ×ª ×¨×©×™××ª ×§×˜×’×•×¨×™×•×ª"""
        categories = set()
        for tool in self.tools_data:
            if tool['category']:
                categories.add(tool['category'])
        
        return sorted(list(categories))
    
    def get_random_tools(self, count=10):
        """×›×œ×™× ××§×¨××™×™×"""
        import random
        
        if count >= len(self.tools_data):
            return self.tools_data
        
        random_tools = random.sample(self.tools_data, count)
        for i, tool in enumerate(random_tools):
            tool['rank'] = i + 1
            tool['relevance_score'] = 1.0
        
        return random_tools
    
    def get_popular_tools(self, top_k=20):
        """×›×œ×™× ×¤×•×¤×•×œ×¨×™×™×"""
        tools_with_pop = []
        
        for tool in self.tools_data:
            if tool['popularity']:
                try:
                    pop_num = int(tool['popularity'].replace('+', '').replace(',', ''))
                    tool_copy = tool.copy()
                    tool_copy['pop_num'] = pop_num
                    tools_with_pop.append(tool_copy)
                except:
                    pass
        
        # ××™×™×Ÿ ×œ×¤×™ ×¤×•×¤×•×œ×¨×™×•×ª
        tools_with_pop.sort(key=lambda x: x['pop_num'], reverse=True)
        
        results = []
        for i, tool in enumerate(tools_with_pop[:top_k]):
            tool['rank'] = i + 1
            tool['relevance_score'] = 1.0
            results.append(tool)
        
        return results
    
    def save_index(self, path='search_index.pkl'):
        """×©××™×¨×ª ××™× ×“×§×¡"""
        data = {
            'tools_data': self.tools_data,
            'embeddings': self.embeddings
        }
        
        with open(path, 'wb') as f:
            pickle.dump(data, f)
        
        logger.info(f"ğŸ’¾ ××™× ×“×§×¡ × ×©××¨ ×‘-{path}")
    
    def load_index(self, path='search_index.pkl'):
        """×˜×¢×™× ×ª ××™× ×“×§×¡"""
        try:
            with open(path, 'rb') as f:
                data = pickle.load(f)
            
            self.tools_data = data['tools_data']
            self.embeddings = data['embeddings']
            
            # ×‘× ×” FAISS index ××—×“×©
            dimension = self.embeddings.shape[1]
            self.index = faiss.IndexFlatIP(dimension)
            self.index.add(self.embeddings.astype('float32'))
            
            logger.info(f"ğŸ“ ××™× ×“×§×¡ × ×˜×¢×Ÿ ×-{path}")
            return True
            
        except Exception as e:
            logger.error(f"×©×’×™××” ×‘×˜×¢×™× ×ª ××™× ×“×§×¡: {e}")
            return False

# ×“×•×’×××•×ª ×œ×©×™××•×©
if __name__ == "__main__":
    print("ğŸš€ ×™×•×¦×¨ ×× ×•×¢ ×—×™×¤×•×© AI...")
    
    try:
        # ×™×¦×•×¨ ×× ×•×¢ ×—×™×¤×•×©
        search_engine = AIToolsSemanticSearch()
        
        # ×“×•×’×××•×ª ×—×™×¤×•×©
        test_queries = [
            "×›×œ×™ ×œ×™×¦×™×¨×ª ×ª××•× ×•×ª",
            "×¦'××˜ ×‘×•×˜ ×¢× AI", 
            "×¢×¨×™×›×ª ×•×™×“××•",
            "×™×¦×™×¨×ª ×œ×•×’×•",
            "×ª×¨×’×•× ×©×¤×•×ª",
            "×›×ª×™×‘×ª ×§×•×“",
            "×—×™× ××™"
        ]
        
        print("\nğŸ” ×‘×“×™×§×ª ×—×™×¤×•×©×™×:")
        
        for query in test_queries:
            print(f"\nğŸ“ ×©××œ×”: '{query}'")
            results = search_engine.search(query, top_k=3)
            
            for result in results:
                score = result['final_score']
                print(f"  â€¢ {result['name']} (×¦×™×•×Ÿ: {score:.3f})")
                print(f"    ğŸ“‚ {result['category']} | ğŸ’° {result['pricing']}")
                print(f"    ğŸ“ {result['description'][:100]}...")
        
        # ×©××•×¨ ××™× ×“×§×¡
        search_engine.save_index()
        
        print(f"\nâœ… ×× ×•×¢ ×—×™×¤×•×© ××•×›×Ÿ ×¢× {len(search_engine.tools_data)} ×›×œ×™×!")
        print("ğŸ’¡ ×¢×›×©×™×• ××¤×©×¨ ×œ×‘× ×•×ª ×××©×§ ××©×ª××©")
        
    except Exception as e:
        print(f"âŒ ×©×’×™××”: {e}")
        print("ğŸ’¡ ×•×“× ×©×§×•×‘×¥ ai_tools_full.db ×§×™×™× ×•××›×™×œ × ×ª×•× ×™×")
